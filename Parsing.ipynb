{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, random\n",
    "from nltk import parse, CFG\n",
    "from cfgen import GrammarModel\n",
    "\n",
    "with open(\"randomsentences.txt\") as text:\n",
    "    sentences = text.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LKJSLFKJDS\n"
     ]
    }
   ],
   "source": [
    "CORPUS_PATH = './../cfgen/resources/corpora/frankenstein.txt'\n",
    "MODEL_ORDER = 2\n",
    "my_model = GrammarModel(CORPUS_PATH, MODEL_ORDER)\n",
    "corpus_split = my_model.corpus.split(\".\")\n",
    "for i in range(len(corpus_split)):\n",
    "    sentence = corpus_split[i]\n",
    "    sentence = \"START\" + sentence + \" END\"\n",
    "    corpus_split[i] = sentence\n",
    "    \n",
    "corpus = \"\\n\".join(corpus_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = my_model.term_rules\n",
    "grammar = CFG.fromstring(rules)\n",
    "dictionary = {}\n",
    "for i in grammar.productions():\n",
    "#     print(i.lhs(), i.rhs())\n",
    "    if (str(i.lhs()) not in dictionary):\n",
    "        dictionary[str(i.lhs())] = i.rhs()[:]\n",
    "    else:\n",
    "        dictionary[str(i.lhs())] += i.rhs()[:]\n",
    "\n",
    "for i in dictionary:\n",
    "    dictionary[i] = set(dictionary[i])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bigram_probs(corpus):\n",
    "    import nltk\n",
    "    count = { }\n",
    "\n",
    "    words = corpus.split()\n",
    "    for word1, word2 in nltk.bigrams(words):\n",
    "        if word1 not in count:\n",
    "            count[word1] = { }\n",
    "        if word2 not in count[word1]:\n",
    "            count[word1][word2] = 1\n",
    "        else:\n",
    "            count[word1][word2] += 1\n",
    "\n",
    "    \n",
    "    # Because corpus START and final END are not originally counted,\n",
    "    # Increase P(END, START) by 1\n",
    "    # Probability of new sentence after previous sentence is always 1.0 (Always possible\n",
    "    try:\n",
    "        count[\"</s>\"][\"<s>\"] += 1\n",
    "    except:\n",
    "        count[\"END\"][\"START\"] += 1\n",
    "\n",
    "    prob = {}\n",
    "    for word1, word2 in nltk.bigrams(words):\n",
    "        if word1 not in prob:\n",
    "            prob[word1] = {}\n",
    "\n",
    "        if word2 not in prob[word1]:\n",
    "            prob[word1][word2] = count[word1][word2]/words.count(word1)\n",
    "\n",
    "\n",
    "    return prob\n",
    "\n",
    "def next_word(word, available_words):\n",
    "    import random\n",
    "    dart = random.random()\n",
    "    possible_words = probs[word]\n",
    "#     print(\"Looking for a word with tag: \", word_tag)\n",
    "    \n",
    "\n",
    "#     make sure list is ordered according to dictionary values\n",
    "    sorted_possibilities = sorted(possible_words.items(), key = lambda i : i[1])\n",
    "#     print(sorted_possibilities)\n",
    "#     for i in sorted_possibilities:\n",
    "# #         print(sorted_possibilities[i])\n",
    "#         if i[1] in available_words:\n",
    "#             print(\"OKKK\")\n",
    "#             return i[1]\n",
    "    nextt = 0.0 # make sure to start from 0.0, build our way to 1.0\n",
    "    for word, prob in sorted_possibilities:\n",
    "        # compute our ranges\n",
    "        last = nextt\n",
    "        current = prob\n",
    "        nextt = last + current\n",
    "\n",
    "        # determine what range the dart landed on, and return that word\n",
    "        if (dart >= last) and (dart < nextt):\n",
    "            #print(\"Range: (%.3f, %.3f) <-- %.3f, word: %s\" % (current, nextt, dart, word))\n",
    "            return word\n",
    "\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_bigram_probs(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DT', 'JJ', 'NN', 'NN', 'VBZ', 'IN', 'DT', 'JJ', 'NN']\n"
     ]
    }
   ],
   "source": [
    "# Useful link: https://github.com/williamgilpin/cfgen\n",
    "tagged = []\n",
    "for i in sentences:\n",
    "    x = nltk.word_tokenize(i)\n",
    "    tagged.append(nltk.pos_tag(x))\n",
    "    \n",
    "\n",
    "for i in range(len(tagged)):\n",
    "    sequence = []\n",
    "    for tupe in tagged[i]:\n",
    "        if not(tupe[1] == \".\"):\n",
    "            sequence.append(tupe[1])\n",
    "    tagged[i] = sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate bigram probabilities\n",
    "probs = get_bigram_probs(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DT', 'NN', 'NN', 'VBZ', 'RB', 'RB']\n"
     ]
    }
   ],
   "source": [
    "random_sequence = random.choice(tagged)\n",
    "\n",
    "# while thing in some_list: some_list.remove(thing)  \n",
    "\n",
    "for i in range(len(random_sequence)):\n",
    "    tag = random_sequence[i]\n",
    "    if not(tag.isalpha()) or not(tag):\n",
    "        random_sequence[i] = \"OOF\"\n",
    "\n",
    "while \"OOF\" in random_sequence: random_sequence.remove(\"OOF\") \n",
    "print(random_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "those queen era relates somewhat firmly \n"
     ]
    }
   ],
   "source": [
    "random_sentence = \"\"\n",
    "word = \"\"\n",
    "for i in random_sequence:\n",
    "    word_possibilities = list(dictionary[i])\n",
    "#     print(word_possibilities)\n",
    "    random_sentence += random.choice(word_possibilities) + \" \"\n",
    "#     word_tag = i\n",
    "#     word = random.choice(word_possibilities)\n",
    "#     word = next_word(word, word_possibilities)\n",
    "#     print(word)\n",
    "\n",
    "print(random_sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
